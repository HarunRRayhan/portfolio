#!/bin/bash

# Prevent multiple simultaneous runs
LOCKFILE="/tmp/$(basename "$0").lock"
if [ -f "$LOCKFILE" ] && ps -p $(cat $LOCKFILE) > /dev/null; then
  echo "$(basename "$0") is still running."
  exit 1
else
  echo $$ > "$LOCKFILE"
  trap "rm -f $LOCKFILE" EXIT
fi

set -e
set -o pipefail

# Get absolute path to script directory, regardless of where it's called from
SCRIPT_DIR="$( cd -- "$( dirname -- "${BASH_SOURCE[0]}" )" &> /dev/null && pwd )"
REPO_ROOT="$(dirname "$SCRIPT_DIR")"

# Usage:
#   ./deploy.sh [KEY=VALUE ...]
#   Example: ./deploy.sh APP_DEBUG=true FOO=bar
# Any key=value pairs passed as arguments will take highest priority in the generated .env file.
# The .env file is generated by merging, in order of precedence (lowest to highest):
#   1. .env.example (base)
#   2. deploy/.env.appprod (if exists)
#   3. deploy/.env.deploy (if exists)
#   4. Inline key=value arguments (provided at runtime)

# Set up logging
LOG_DIR="$SCRIPT_DIR/log"
mkdir -p "$LOG_DIR"
# Archive previous deploy.log if it exists
if [ -f "$LOG_DIR/deploy.log" ]; then
  mv "$LOG_DIR/deploy.log" "$LOG_DIR/deploy-$(date '+%Y%m%d-%H%M%S').log"
fi
LOG_FILE="$LOG_DIR/deploy.log"
exec > >(tee -a "$LOG_FILE") 2>&1

# Load environment variables
if [ -f "$SCRIPT_DIR/.env.deploy" ]; then
  set -a
  . "$SCRIPT_DIR/.env.deploy"
  set +a
fi

# Always resolve SSH_KEY to absolute path after loading .env.deploy
if [ -n "$SSH_KEY" ] && [[ "$SSH_KEY" != /* ]]; then
  SSH_KEY="$SCRIPT_DIR/$SSH_KEY"
fi
export SSH_KEY

echo "[DEBUG] SSH_KEY resolved to: $SSH_KEY"

# Colors have been completely removed

# Signature and start time
SCRIPT_START_TIME=$(date +%s)
echo -e "\n==============================================="
echo -e "   ðŸš€ Harun's Portfolio Deployment Script ðŸš€"
echo -e "===============================================\n"
echo "Started at: $(date)"

# Remove associative array, use indexed array for step times
STEP_TIMES=()

# Helper: Print step header, track and print step time
step() {
  STEP_NUM=$1
  STEP_NAME="$2"
  echo -e "\n+++++++++++++++++++++++++++++++++++++++++++++++"
  printf '+++   STEP %d: %s   +++\n' "$STEP_NUM" "$STEP_NAME"
  echo -e "++++++++++++++++++++++++++++++++++++++++++++++\n"
  STEP_START_TIME=$(date +%s)
}

# Helper: Print success info to terminal only
success() {
  echo -e "$1"
  STEP_END_TIME=$(date +%s)
  STEP_DURATION=$((STEP_END_TIME - STEP_START_TIME))
  echo -e "Step took $STEP_DURATION seconds.\n"
  STEP_TIMES+=("$STEP_DURATION")
}

# Helper: Print error info to terminal only
fail() {
  echo -e "$1"
  STEP_END_TIME=$(date +%s)
  STEP_DURATION=$((STEP_END_TIME - STEP_START_TIME))
  echo -e "Step took $STEP_DURATION seconds.\n"
  STEP_TIMES+=("$STEP_DURATION")
}

# At the end, print total time
print_total_time() {
  SCRIPT_END_TIME=$(date +%s)
  TOTAL_DURATION=$((SCRIPT_END_TIME - SCRIPT_START_TIME))
  echo -e "\n==============================================="
  echo -e "   ðŸŽ‰ Deployment completed in $TOTAL_DURATION seconds! ðŸŽ‰"
  echo -e "===============================================\n"
  for i in $(seq 1 ${#STEP_TIMES[@]}); do
    echo "Step $i took: ${STEP_TIMES[$((i-1))]:-N/A} seconds"
  done
}

# Function to execute SSH commands
execute_ssh() {
    ssh -o StrictHostKeyChecking=no -i "$SSH_KEY" "$REMOTE_USER@$REMOTE_HOST" "$1"
}

# Function to clone or update the git repository on the server
clone_or_update_repo() {
    execute_ssh "if [ ! -d $APP_DIR/.git ]; then \
        if [ -d $APP_DIR ]; then \
            rm -rf $APP_DIR/* $APP_DIR/.[!.]* $APP_DIR/..?* 2>/dev/null || true; \
        else \
            mkdir -p $APP_DIR; \
        fi; \
        git clone --branch $GIT_BRANCH $GIT_REPO $APP_DIR; \
    else \
        cd $APP_DIR && git reset --hard HEAD && git clean -fd && git fetch origin && git checkout $GIT_BRANCH && git pull origin $GIT_BRANCH; \
    fi"
}

# Function to robustly merge env files
merge_env_files() {
    # $1 = base file, $2 = override file, $3 = output file
    if ! cmp -s "$1" "$3"; then
        cp "$1" "$3"
    fi
    if [ -f "$2" ]; then
        while IFS= read -r line; do
            # Only process non-empty, non-comment lines
            if [[ "$line" =~ ^[A-Za-z_][A-Za-z0-9_]*= ]]; then
                key="${line%%=*}"
                # Remove any existing key (even if commented out)
                sed -i '' "/^$key=/d" "$3"
                # Append the new/override value
                echo "$line" >> "$3"
            fi
        done < "$2"
    fi
}

# Helper: Overlay only inline-provided envs (those set on the command line)
overlay_inline_envs() {
    # Save current IFS
    OLDIFS=$IFS
    IFS=' '
    # Get the list of inline envs from the command line
    for arg in $(ps -o args= -p $$); do
        if [[ "$arg" =~ ^[A-Za-z_][A-Za-z0-9_]*= ]]; then
            key="${arg%%=*}"
            value="${arg#*=}"
            sed -i '' "/^$key=/d" "$SCRIPT_DIR/.env"
            echo "$key=$value" >> "$SCRIPT_DIR/.env"
        fi
    done
    IFS=$OLDIFS
}

# Add this helper function near the top of the script
wait_for_app_container() {
  local timeout=60
  local elapsed=0
  while [ $elapsed -lt $timeout ]; do
    DOCKER_COMPOSE_CMD=$(docker_compose_run "./docker/docker-compose.yml" "ps --services --filter 'status=running' | grep '^app$'")
    STATUS=$(execute_ssh "cd $APP_DIR && $DOCKER_COMPOSE_CMD")
    if [ "$STATUS" = "app" ]; then
      return 0
    fi
    sleep 2
    elapsed=$((elapsed+2))
  done
  echo "App container did not start within $timeout seconds." >&2
  return 1
}

wait_forcheck_app_container_running() {
  local timeout=60
  local elapsed=0
  while [ $elapsed -lt $timeout ]; do
    DOCKER_COMPOSE_CMD=$(docker_compose_run "./docker/docker-compose.yml" "ps --services --filter 'status=running' | grep '^app$'")
    STATUS=$(execute_ssh "cd $APP_DIR && $DOCKER_COMPOSE_CMD")
    if [ "$STATUS" = "app" ]; then
      return 0
    fi
    sleep 1
    elapsed=$((elapsed + 1))
  done
  echo "App container did not start within $timeout seconds." >&2
  return 1
}

#-------------------------------------------------------------------------------
# Helper Functions
#-------------------------------------------------------------------------------
# Function to generate Docker environment variables string
get_docker_env_vars() {
  echo "POSTGRES_DB=$POSTGRES_DB \
  POSTGRES_USER=$POSTGRES_USER \
  POSTGRES_PASSWORD=$POSTGRES_PASSWORD \
  MIN_APP_INSTANCES=$MIN_APP_INSTANCES \
  MAX_APP_INSTANCES=$MAX_APP_INSTANCES \
  APP_CPU_LIMIT=$APP_CPU_LIMIT \
  APP_MEMORY_LIMIT=$APP_MEMORY_LIMIT \
  DB_CPU_LIMIT=$DB_CPU_LIMIT \
  DB_MEMORY_LIMIT=$DB_MEMORY_LIMIT \
  MAX_APP_CPU_LIMIT=$MAX_APP_CPU_LIMIT \
  MAX_APP_MEMORY_LIMIT=$MAX_APP_MEMORY_LIMIT \
  MAX_NGINX_CPU_LIMIT=$MAX_NGINX_CPU_LIMIT \
  MAX_NGINX_MEMORY_LIMIT=$MAX_NGINX_MEMORY_LIMIT \
  MAX_DB_CPU_LIMIT=$MAX_DB_CPU_LIMIT \
  MAX_DB_MEMORY_LIMIT=$MAX_DB_MEMORY_LIMIT"
}

# Execute Docker Compose command with proper environment variables
docker_compose_exec() {
  local compose_file="$1"
  local service="$2"
  local command="$3"
  local docker_env_vars=$(get_docker_env_vars)

  echo "$docker_env_vars docker-compose -f $compose_file exec -T $service $command"
}

# Run Docker Compose command with proper environment variables
docker_compose_run() {
  local compose_file="$1"
  local command="$2"
  local docker_env_vars=$(get_docker_env_vars)

  echo "$docker_env_vars docker-compose -f $compose_file --env-file ./docker/.env $command"
}

# Helper to check if a container is running
is_container_running() {
  local name="$1"
  docker ps --format '{{.Names}}' | grep -q "^${name}$"
}

# 1. Start
step 1 "Starting deployment"
echo "[DEBUG] SSH_KEY resolved to: $SSH_KEY"

# 2. Initialize server with required directories and Docker
step 2 "Initializing server with required directories and Docker"

# Create required directories if they don't exist
execute_ssh "sudo mkdir -p $APP_DIR"
execute_ssh "sudo chown -R ubuntu:ubuntu $APP_DIR || true"

# Install Docker if not already installed
if ! execute_ssh "command -v docker &> /dev/null"; then
  echo "Docker not found, installing..."
  
  # Wait for any existing apt/dpkg processes to finish
  echo "Checking for existing package manager processes..."
  max_attempts=30
  attempt=1
  while execute_ssh "pgrep -f apt-get >/dev/null 2>&1 || pgrep -f dpkg >/dev/null 2>&1 || lsof /var/lib/dpkg/lock-frontend >/dev/null 2>&1 || lsof /var/lib/apt/lists/lock >/dev/null 2>&1 || lsof /var/lib/dpkg/lock >/dev/null 2>&1 || [ -f /var/lib/apt/lists/lock ] || [ -f /var/lib/dpkg/lock ] || [ -f /var/lib/dpkg/lock-frontend ]"; do
    echo "Waiting for other package manager processes to finish... (attempt $attempt of $max_attempts)"
    if [ "$attempt" -ge "$max_attempts" ]; then
      echo "Maximum attempts reached. Trying to proceed anyway..."
      execute_ssh "sudo rm -f /var/lib/apt/lists/lock /var/lib/dpkg/lock /var/lib/dpkg/lock-frontend"
      break
    fi
    attempt=$((attempt+1))
    sleep 20
  done
  
  echo "Package manager is available now. Installing Docker..."
  execute_ssh "sudo apt-get update && \
    sudo apt-get install -y apt-transport-https ca-certificates curl software-properties-common && \
    curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - && \
    sudo add-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/ubuntu \$(lsb_release -cs) stable\" && \
    sudo apt-get update && \
    sudo apt-get install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin && \
    sudo systemctl enable docker && \
    sudo systemctl start docker"
  echo "Docker installed successfully"
  
  # Wait for Docker to be fully initialized
  echo "Waiting for Docker to be fully initialized..."
  for i in {1..30}; do
    if execute_ssh "sudo docker ps &>/dev/null"; then
      echo "Docker is now ready."
      break
    fi
    echo "Waiting for Docker to be ready... ($i/30)"
    sleep 5
  done
fi

# 3. Ensure ubuntu user is in the docker group for Docker access
step 3 "Ensuring ubuntu user is in the docker group"
execute_ssh "sudo usermod -aG docker ubuntu"

# 4. Use existing .env.appprod file as main app .env
step 4 "Using existing .env.appprod file as main app .env"
if [ -f "$SCRIPT_DIR/.env.appprod" ]; then
    cp "$SCRIPT_DIR/.env.appprod" "$REPO_ROOT/.env"
    echo "Using .env.appprod file for main application configuration"
else
    echo "Warning: .env.appprod not found, using .env.example"
    cp "$REPO_ROOT/.env.example" "$REPO_ROOT/.env"
fi

# 5. Ensure resources/views exists with a real Blade placeholder for Laravel
step 5 "Ensuring resources/views exists with placeholder"
mkdir -p "$REPO_ROOT/resources/views"
if [ ! -f "$REPO_ROOT/resources/views/placeholder.blade.php" ]; then
  echo "{{-- Placeholder view to satisfy Laravel --}}" > "$REPO_ROOT/resources/views/placeholder.blade.php"
fi

# 6. Check Node.js version before build
step 6 "Checking Node.js version"

# Configuration - can be overridden via environment variables
MIN_NODE_VERSION=${MIN_NODE_VERSION:-18}
PREFERRED_NODE_VERSION=${PREFERRED_NODE_VERSION:-"lts"}
NVM_VERSION=${NVM_VERSION:-"latest"}

# Helper function to source nvm
source_nvm() {
  local nvm_locations=(
    "$HOME/.nvm/nvm.sh"
    "$NVM_DIR/nvm.sh"
    "/usr/local/opt/nvm/nvm.sh"
    "/opt/homebrew/opt/nvm/nvm.sh"
    "/usr/share/nvm/nvm.sh"
  )
  
  for location in "${nvm_locations[@]}"; do
    if [ -s "$location" ]; then
      echo "Sourcing nvm from: $location"
      . "$location"
      return 0
    fi
  done
  return 1
}

# Check if nvm is available
if ! command -v nvm &> /dev/null; then
  echo "nvm not found, attempting to source from common locations..."
  
  if ! source_nvm; then
    echo "nvm not found in standard locations. Installing nvm..."
    
    # Get latest nvm version if not specified
    if [ "$NVM_VERSION" = "latest" ]; then
      NVM_INSTALL_URL="https://raw.githubusercontent.com/nvm-sh/nvm/master/install.sh"
    else
      NVM_INSTALL_URL="https://raw.githubusercontent.com/nvm-sh/nvm/v${NVM_VERSION}/install.sh"
    fi
    
    curl -o- "$NVM_INSTALL_URL" | bash
    
    # Source nvm after installation
    export NVM_DIR="$HOME/.nvm"
    source_nvm || {
      echo "Failed to source nvm after installation"
      exit 1
    }
  fi
fi

# Get current Node.js version
get_node_major_version() {
  node -v 2>/dev/null | sed 's/v//;s/\..*//' || echo "0"
}

CURRENT_NODE_VERSION=$(get_node_major_version)
echo "Current Node.js version: $(node -v 2>/dev/null || echo 'not installed')"
echo "Required minimum version: ${MIN_NODE_VERSION}"

# Check if current version meets requirements
if [ "$CURRENT_NODE_VERSION" -lt "$MIN_NODE_VERSION" ]; then
  echo "Node.js >= ${MIN_NODE_VERSION} is required."
  
  if command -v nvm &> /dev/null; then
    echo "Attempting to install/switch to Node.js ${PREFERRED_NODE_VERSION} using nvm..."
    
    # Install and use the preferred version
    nvm install "$PREFERRED_NODE_VERSION"
    nvm use "$PREFERRED_NODE_VERSION"
    
    # Verify the installation
    NEW_NODE_VERSION=$(get_node_major_version)
    if [ "$NEW_NODE_VERSION" -lt "$MIN_NODE_VERSION" ]; then
      fail "Failed to install Node.js >= ${MIN_NODE_VERSION} using nvm. Current: $(node -v)"
      exit 1
    else
      echo "Successfully switched to Node.js $(node -v)"
    fi
  else
    fail "nvm is not available. Please install Node.js >= ${MIN_NODE_VERSION} manually."
    exit 1
  fi
else
  echo "Node.js version check passed: $(node -v)"
fi

success "Node.js version check passed: $(node -v)"

# 7. Build frontend locally
step 7 "Building frontend locally"
cd "$REPO_ROOT"

# Empty out public/build/assets if it exists
if [ -d "public/build/assets" ]; then
  echo "[INFO] Emptying public/build/assets before build..."
  rm -rf public/build/assets/*
fi

# Backup existing .env file if it exists
if [ -f "$REPO_ROOT/.env" ]; then
  echo "[INFO] Backing up existing .env file..."
  cp "$REPO_ROOT/.env" "$REPO_ROOT/.env.backup"
fi

# Copy .env.appprod to .env for the build process
cp "$SCRIPT_DIR/.env.appprod" "$REPO_ROOT/.env"

npm ci && npm run build
BUILD_STATUS=$?

# Restore the original .env file if backup exists
if [ -f "$REPO_ROOT/.env.backup" ]; then
  echo "[INFO] Restoring original .env file..."
  cp "$REPO_ROOT/.env.backup" "$REPO_ROOT/.env"
  rm "$REPO_ROOT/.env.backup"
else
  # Remove the .env file if no backup existed
  rm -f "$REPO_ROOT/.env"
fi

cd "$SCRIPT_DIR"
if [ $BUILD_STATUS -ne 0 ]; then
  echo "Frontend build failed. Aborting deploy."
  exit 1
fi
success "Frontend built successfully."

# 8. Upload static assets to Cloudflare R2
step 8 "Uploading static assets to Cloudflare R2"
if [ -z "$R2_BUCKET_NAME" ] || [ -z "$R2_S3_ENDPOINT" ] || [ -z "$R2_ACCESS_KEY_ID" ] || [ -z "$R2_SECRET_ACCESS_KEY" ]; then
  echo "R2_BUCKET_NAME, R2_S3_ENDPOINT, R2_ACCESS_KEY_ID, or R2_SECRET_ACCESS_KEY not set. Aborting."
  exit 1
fi

export AWS_ACCESS_KEY_ID="$R2_ACCESS_KEY_ID"
export AWS_SECRET_ACCESS_KEY="$R2_SECRET_ACCESS_KEY"

# Ensure proper content types for different file types
echo "Uploading build assets with proper content types..."
aws s3 sync "$REPO_ROOT/public/build" "s3://$R2_BUCKET_NAME/build" --endpoint-url "$R2_S3_ENDPOINT" --delete --acl public-read

# Upload JS files with proper content type
echo "Setting proper content types for JavaScript files..."
find "$REPO_ROOT/public/build" -name "*.js" -type f | while read -r file; do
  relative_path="${file#$REPO_ROOT/public/}"
  aws s3 cp "$file" "s3://$R2_BUCKET_NAME/$relative_path" --endpoint-url "$R2_S3_ENDPOINT" --content-type "application/javascript" --acl public-read
done

# Upload CSS files with proper content type
echo "Setting proper content types for CSS files..."
find "$REPO_ROOT/public/build" -name "*.css" -type f | while read -r file; do
  relative_path="${file#$REPO_ROOT/public/}"
  aws s3 cp "$file" "s3://$R2_BUCKET_NAME/$relative_path" --endpoint-url "$R2_S3_ENDPOINT" --content-type "text/css" --acl public-read
done

# Upload other static assets
aws s3 sync "$REPO_ROOT/public/fonts" "s3://$R2_BUCKET_NAME/fonts" --endpoint-url "$R2_S3_ENDPOINT" --delete --acl public-read
aws s3 sync "$REPO_ROOT/public/images" "s3://$R2_BUCKET_NAME/images" --endpoint-url "$R2_S3_ENDPOINT" --delete --acl public-read

success "Static assets uploaded to Cloudflare R2."

# 9. Ensure resources/views exists with a real Blade placeholder for Laravel
step 9 "Ensuring resources/views exists with placeholder"
mkdir -p "$REPO_ROOT/resources/views"
if [ ! -f "$REPO_ROOT/resources/views/placeholder.blade.php" ]; then
  echo "{{-- Placeholder view to satisfy Laravel --}}" > "$REPO_ROOT/resources/views/placeholder.blade.php"
fi
success "Laravel views directory prepared."

# 10. Clone or update repo on server
step 10 "Cloning or updating repository on server"
clone_or_update_repo

# Check for required Docker context files after clone
execute_ssh "if [ ! -f $APP_DIR/docker/Dockerfile ] || [ ! -f $APP_DIR/docker/wait-for-db.sh ]; then echo '[ERROR] Required Docker context files missing after git clone. Ensure docker/Dockerfile and docker/wait-for-db.sh are committed to the repo.' >&2; exit 1; fi"

# 11. Ensure host storage directory has correct structure and permissions (after clone)
step 11 "Ensuring host storage directory structure and permissions"
HOST_STORAGE_DIR="/opt/portfolio/storage"
execute_ssh "if [ -d '$HOST_STORAGE_DIR' ]; then \
  mkdir -p '$HOST_STORAGE_DIR/framework/views' '$HOST_STORAGE_DIR/framework/cache' '$HOST_STORAGE_DIR/logs'; \
  sudo chown -R 82:82 '$HOST_STORAGE_DIR'; \
  sudo chmod -R 775 '$HOST_STORAGE_DIR'; \
else \
  echo '[WARN] Host storage directory $HOST_STORAGE_DIR does not exist!'; \
fi"

# 12. Upload remaining public files to server (excluding build, fonts, images)
step 12 "Uploading remaining public files to server"
# Only upload files in public/ that are not in build, fonts, images
tmp_sync_dir="$SCRIPT_DIR/public-server-sync"
rm -rf "$tmp_sync_dir"
mkdir -p "$tmp_sync_dir"
cd "$REPO_ROOT/public"
find . -maxdepth 1 -type f -exec cp {} "$tmp_sync_dir/" \;
# Always include manifest.json if it exists in build
test -f "$REPO_ROOT/public/build/manifest.json" && cp "$REPO_ROOT/public/build/manifest.json" "$tmp_sync_dir/"
cd "$SCRIPT_DIR"
tar --no-xattrs -czf public-server-files.tar.gz -C "$tmp_sync_dir" .
scp -o StrictHostKeyChecking=no -i "$SSH_KEY" public-server-files.tar.gz "$REMOTE_USER@$REMOTE_HOST:$APP_DIR/public-server-files.tar.gz"
execute_ssh "mkdir -p $APP_DIR/public && tar xzf $APP_DIR/public-server-files.tar.gz -C $APP_DIR/public && rm $APP_DIR/public-server-files.tar.gz"
rm -rf "$tmp_sync_dir" public-server-files.tar.gz

success "Remaining public files uploaded to server."

# 13. Set up docker env on the server & start containers
step 13 "Setting up docker environment on server & starting containers"
execute_ssh "mkdir -p $APP_DIR/docker $APP_DIR/docker/nginx $APP_DIR/bootstrap/cache $APP_DIR/storage $APP_DIR/storage/logs $APP_DIR/storage/framework/sessions $APP_DIR/storage/framework/views $APP_DIR/storage/framework/cache $APP_DIR/storage/framework/cache/data"

# Copy docker files directly to /opt/portfolio/docker, not to /opt/portfolio/deploy/docker
scp -o StrictHostKeyChecking=no -i "$SSH_KEY" "$REPO_ROOT/docker/docker-compose.yml" "$REMOTE_USER@$REMOTE_HOST:$APP_DIR/docker/docker-compose.yml"
scp -o StrictHostKeyChecking=no -i "$SSH_KEY" "$REPO_ROOT/docker/Dockerfile" "$REMOTE_USER@$REMOTE_HOST:$APP_DIR/docker/Dockerfile"
scp -o StrictHostKeyChecking=no -i "$SSH_KEY" "$REPO_ROOT/docker/wait-for-db.sh" "$REMOTE_USER@$REMOTE_HOST:$APP_DIR/docker/wait-for-db.sh"

# Set permissions for Nginx directories (use nginx:nginx)
# execute_ssh "cd $APP_DIR && sudo chown -R nginx:nginx public bootstrap storage || true && sudo chmod -R 755 public bootstrap storage || true"

# 14. Upload Nginx and Traefik config files for blue-green
step 14 "Uploading Nginx and Traefik config files for blue-green deployment"
execute_ssh "mkdir -p $APP_DIR/docker/nginx"
execute_ssh "rm -rf $APP_DIR/docker/nginx/blue.conf $APP_DIR/docker/nginx/green.conf $APP_DIR/docker/traefik-dynamic.yml"
scp -o StrictHostKeyChecking=no -i "$SSH_KEY" "$REPO_ROOT/docker/nginx/blue.conf" "$REMOTE_USER@$REMOTE_HOST:$APP_DIR/docker/nginx/blue.conf"
scp -o StrictHostKeyChecking=no -i "$SSH_KEY" "$REPO_ROOT/docker/nginx/green.conf" "$REMOTE_USER@$REMOTE_HOST:$APP_DIR/docker/nginx/green.conf"
scp -o StrictHostKeyChecking=no -i "$SSH_KEY" "$REPO_ROOT/docker/traefik-dynamic.yml" "$REMOTE_USER@$REMOTE_HOST:$APP_DIR/docker/traefik-dynamic.yml"

# Verify config files exist
step 15 "Verifying configuration files were uploaded correctly"
execute_ssh "ls -la $APP_DIR/docker/nginx/blue.conf $APP_DIR/docker/nginx/green.conf $APP_DIR/docker/traefik-dynamic.yml && echo 'Confirmed: All config files exist in correct locations'"

# 16. Copy existing .env.appprod file
step 16 "Copying existing .env.appprod file"
# Remove any existing .env on the server before copying
execute_ssh "rm -f $APP_DIR/.env"

# Copy the existing .env.appprod file which already has the correct Laravel configuration
scp -o StrictHostKeyChecking=no -i "$SSH_KEY" "$SCRIPT_DIR/.env.appprod" "$REMOTE_USER@$REMOTE_HOST:$APP_DIR/.env"

# Also copy .env.deploy to .env in the docker directory for Compose variable substitution
scp -o StrictHostKeyChecking=no -i "$SSH_KEY" "$SCRIPT_DIR/.env.deploy" "$REMOTE_USER@$REMOTE_HOST:$APP_DIR/docker/.env"

# Ensure manifest.json is present before Docker build
execute_ssh "mkdir -p $APP_DIR/public/build"
scp -o StrictHostKeyChecking=no -i "$SSH_KEY" "$REPO_ROOT/public/build/manifest.json" "$REMOTE_USER@$REMOTE_HOST:$APP_DIR/public/build/manifest.json"

# 17. Generate .env.db for the db service
step 17 "Generating .env.db for db service"
execute_ssh "cd $APP_DIR && grep -E '^(POSTGRES_DB|POSTGRES_USER|POSTGRES_PASSWORD)=' docker/.env > ./docker/.env.db && chmod 600 ./docker/.env.db"

# Create a debug step to verify file creation
step 18 "Verifying .env.db was created in the correct location"
execute_ssh "ls -la $APP_DIR/docker/.env.db && echo 'Confirmed: .env.db exists in correct location'"

# 19. Manage SSL certificates with Let's Encrypt and S3 storage
step 19 "Managing SSL certificates with Let's Encrypt and S3 storage"

# Upload SSL management files to server
scp -o StrictHostKeyChecking=no -i "$SSH_KEY" "$SCRIPT_DIR/ssl-manager.sh" "$REMOTE_USER@$REMOTE_HOST:$APP_DIR/deploy/ssl-manager.sh"
scp -o StrictHostKeyChecking=no -i "$SSH_KEY" "$SCRIPT_DIR/ssl-renewal.service" "$REMOTE_USER@$REMOTE_HOST:$APP_DIR/deploy/ssl-renewal.service"
scp -o StrictHostKeyChecking=no -i "$SSH_KEY" "$SCRIPT_DIR/ssl-renewal.timer" "$REMOTE_USER@$REMOTE_HOST:$APP_DIR/deploy/ssl-renewal.timer"

execute_ssh "chmod +x $APP_DIR/deploy/ssl-manager.sh"

# Install AWS CLI if not present
if ! execute_ssh "command -v aws &> /dev/null"; then
  echo "Installing AWS CLI..."
  execute_ssh "curl 'https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip' -o 'awscliv2.zip' && \
    sudo apt-get update && sudo apt-get install -y unzip && \
    unzip awscliv2.zip && \
    sudo ./aws/install && \
    rm -rf awscliv2.zip aws"
fi

# Set up AWS credentials for SSL management
execute_ssh "mkdir -p ~/.aws"
execute_ssh "cat > ~/.aws/credentials << EOF
[default]
aws_access_key_id = $AWS_ACCESS_KEY_ID
aws_secret_access_key = $AWS_SECRET_ACCESS_KEY
region = us-east-1
EOF"

execute_ssh "cat > ~/.aws/config << EOF
[default]
region = us-east-1
output = json
EOF"

# Create Traefik letsencrypt directory
execute_ssh "mkdir -p $APP_DIR/docker/letsencrypt"

# Run SSL certificate management with automatic backup
echo "Running SSL certificate management with automatic S3 backup..."
execute_ssh "cd $APP_DIR/deploy && \
  AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID \
  AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY \
  CONFIG_BUCKET_NAME=$CONFIG_BUCKET_NAME \
  DOMAIN=harun.dev \
  ./ssl-manager.sh manage"

# Wait for certificate generation and then backup to S3
echo "Waiting for SSL certificate generation to complete..."
sleep 30

# Backup SSL certificates to S3 automatically using the new backup command
echo "Backing up SSL certificates to S3..."
execute_ssh "cd $APP_DIR/deploy && \
  AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID \
  AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY \
  CONFIG_BUCKET_NAME=$CONFIG_BUCKET_NAME \
  DOMAIN=harun.dev \
  ./ssl-manager.sh backup"

# Set up automatic SSL renewal system
echo "Setting up automatic SSL renewal system..."
execute_ssh "cd $APP_DIR/deploy && \
  sudo cp ssl-renewal.service /etc/systemd/system/ && \
  sudo cp ssl-renewal.timer /etc/systemd/system/ && \
  sudo systemctl daemon-reload && \
  sudo systemctl enable ssl-renewal.timer && \
  sudo systemctl start ssl-renewal.timer"

# Verify SSL renewal timer is active
execute_ssh "sudo systemctl status ssl-renewal.timer --no-pager"

success "SSL certificate management completed with automatic backup and renewal"

# 20. Ensure required Laravel cache and storage directories exist and are writable by www-data
step 20 "Ensuring Laravel cache and storage directories exist and are writable"
execute_ssh "cd $APP_DIR && \
  mkdir -p storage/framework/views storage/framework/cache storage/logs bootstrap/cache && \
  sudo chown -R www-data:www-data storage bootstrap/cache && \
  sudo chmod -R 775 storage bootstrap/cache"

# 21. Execute deployment commands
step 21 "Executing deployment commands"
# Create a multi-line command with proper Docker environment variables
DOCKER_COMPOSE_FILE="./docker/docker-compose.yml"

# Execute the commands in sequence for blue-green deployment
execute_ssh "cd $APP_DIR && \
    docker compose -f $DOCKER_COMPOSE_FILE down && \
    docker compose -f $DOCKER_COMPOSE_FILE build --no-cache && \
    docker compose -f $DOCKER_COMPOSE_FILE up -d && \
    docker compose -f $DOCKER_COMPOSE_FILE ps"
# Remove the .env from the repo root after build
rm -f "$REPO_ROOT/.env"

# Update APP_KEY in .env on the server
# Generate Laravel application key using php_blue container
execute_ssh "cd $APP_DIR && APP_KEY=\$(docker compose -f docker/docker-compose.yml exec -T php_blue php artisan key:generate --show) && \
    echo Found APP_KEY: \$APP_KEY && \
    (grep -q '^APP_KEY=' .env && sed -i 's|^APP_KEY=.*|APP_KEY=\$APP_KEY|' .env || echo APP_KEY=\$APP_KEY >> .env)"

# Run Laravel artisan commands for optimization and setup using php_blue container
DOCKER_COMPOSE_FILE="./docker/docker-compose.yml"

# Fix permissions for Laravel cache directories - using Docker to handle permissions with a single command
execute_ssh "cd $APP_DIR && docker compose -f $DOCKER_COMPOSE_FILE exec -T php_blue sh -c 'mkdir -p /var/www/html/bootstrap/cache /var/www/html/storage/framework/cache /var/www/html/storage/framework/cache/data /var/www/html/storage/framework/sessions /var/www/html/storage/framework/views /var/www/html/storage/logs && chown -R www-data:www-data /var/www/html/storage /var/www/html/bootstrap/cache && chmod -R 777 /var/www/html/storage /var/www/html/bootstrap/cache'"

# Execute artisan commands using php_blue container
execute_ssh "cd $APP_DIR && \
    docker compose -f $DOCKER_COMPOSE_FILE exec -T php_blue php artisan config:cache && \
    docker compose -f $DOCKER_COMPOSE_FILE exec -T php_blue php artisan route:cache && \
    docker compose -f $DOCKER_COMPOSE_FILE exec -T php_blue php artisan view:cache && \
    docker compose -f $DOCKER_COMPOSE_FILE exec -T php_blue php artisan migrate --force && \
    docker compose -f $DOCKER_COMPOSE_FILE exec -T php_blue sh -c 'if [ ! -L /var/www/html/public/storage ]; then php artisan storage:link; else echo Storage link already exists, skipping creation; fi'"

# 22. Check container status
step 22 "Checking blue-green container status"
execute_ssh "cd $APP_DIR && docker compose -f docker/docker-compose.yml ps"
echo "Waiting for containers to be ready..."
sleep 10

# 23. Ensure wait-for-db.sh is executable in the container
step 23 "Ensuring wait-for-db.sh is executable in the container"
execute_ssh "cd $APP_DIR && docker compose -f docker/docker-compose.yml exec -T php_blue sh -c 'chmod +x ./wait-for-db.sh && php artisan cache:clear'"

# 24. Ensure proper Laravel cache configuration
step 24 "Ensuring proper Laravel cache configuration"

# Create all required Laravel cache directories with proper permissions and add .gitkeep files to ensure they exist
execute_ssh "cd $APP_DIR && docker compose -f docker/docker-compose.yml exec -T php_blue sh -c '
    # Create all required Laravel directory structure
    mkdir -p /var/www/html/storage/app/public \
    /var/www/html/storage/framework/cache \
    /var/www/html/storage/framework/cache/data \
    /var/www/html/storage/framework/sessions \
    /var/www/html/storage/framework/testing \
    /var/www/html/storage/framework/views \
    /var/www/html/storage/logs \
    /var/www/html/bootstrap/cache && \
    \
    # Add .gitkeep files to ensure directories exist and are tracked
    touch /var/www/html/storage/framework/cache/.gitkeep \
    /var/www/html/storage/framework/cache/data/.gitkeep \
    /var/www/html/storage/framework/sessions/.gitkeep \
    /var/www/html/storage/framework/testing/.gitkeep \
    /var/www/html/storage/framework/views/.gitkeep \
    /var/www/html/storage/logs/.gitkeep \
    /var/www/html/bootstrap/cache/.gitkeep && \
    \
    # Set proper permissions
    chmod -R 777 /var/www/html/storage && \
    chmod -R 777 /var/www/html/bootstrap/cache && \
    chown -R www-data:www-data /var/www/html/storage /var/www/html/bootstrap/cache && \
    \
    # Ensure cache driver is set to file in the .env file
    grep -q \"CACHE_DRIVER=file\" /var/www/html/.env || sed -i \"s/CACHE_DRIVER=.*/CACHE_DRIVER=file/\" /var/www/html/.env'"

# Laravel setup is now handled by the entrypoint scripts
echo "Laravel cache and storage setup is handled by the PHP container entrypoint script."

# 25. Wait for the database to be ready and test connection
step 25 "Testing database connection from php_blue container"
execute_ssh "cd $APP_DIR && docker compose -f docker/docker-compose.yml exec -T php_blue php artisan migrate:status"

success "Deployment completed!"

# 26. Skip Cloudflare Worker R2 Bucket Binding (already done by Terraform)
step 26 "Skipping Cloudflare Worker R2 Bucket Binding (already done by Terraform)"

echo "Skipping Cloudflare Worker R2 bucket binding as it's already configured by Terraform during infrastructure creation."

# 27. Purge CDN Cache (Cloudflare)
step 27 "Purging CDN Cache (Cloudflare)"
if [ -z "$CLOUDFLARE_ZONE_ID" ] || [ -z "$CLOUDFLARE_API_TOKEN" ]; then
  echo "Skipping Cloudflare CDN purge - missing CLOUDFLARE_ZONE_ID or CLOUDFLARE_API_TOKEN"
  echo "To enable Cloudflare cache purging, add the following to your .env.deploy file:"
  echo "CLOUDFLARE_API_TOKEN=your_api_token"
  echo "CLOUDFLARE_ZONE_ID=your_zone_id"
else
  echo "Attempting to purge Cloudflare cache for zone ID $CLOUDFLARE_ZONE_ID"
  if [ -n "$CLOUDFLARE_API_TOKEN" ]; then
    echo "Using API Token authentication method..."
    RESULT=$(curl -s -X POST \
      "https://api.cloudflare.com/client/v4/zones/$CLOUDFLARE_ZONE_ID/purge_cache" \
      -H "Authorization: Bearer $CLOUDFLARE_API_TOKEN" \
      -H "Content-Type: application/json" \
      --data '{"purge_everything":true}')

    # Parse JSON properly to check for success
    SUCCESS=$(echo "$RESULT" | grep -o '"success":[^,}]*' | cut -d ':' -f2 | tr -d ' ')
    if [[ "$SUCCESS" == "true" ]]; then
      echo "Cloudflare cache purged successfully!"
    else
      echo "Failed to purge Cloudflare cache. Response: $RESULT"
    fi
  elif [ -n "$CLOUDFLARE_EMAIL" ] && [ -n "$CLOUDFLARE_API_KEY" ]; then
    echo "Using API Key authentication method..."
    RESULT=$(curl -s -X POST \
      "https://api.cloudflare.com/client/v4/zones/$CLOUDFLARE_ZONE_ID/purge_cache" \
      -H "X-Auth-Email: $CLOUDFLARE_EMAIL" \
      -H "X-Auth-Key: $CLOUDFLARE_API_KEY" \
      -H "Content-Type: application/json" \
      --data '{"purge_everything":true}')

    # Parse JSON properly to check for success
    SUCCESS=$(echo "$RESULT" | grep -o '"success":[^,}]*' | cut -d ':' -f2 | tr -d ' ')
    if [[ "$SUCCESS" == "true" ]]; then
      echo "Cloudflare cache purged successfully!"
    else
      echo "Failed to purge Cloudflare cache. Response: $RESULT"
    fi
  else
    echo "Missing Cloudflare authentication credentials. Please provide either API Token or Email + API Key."
  fi
fi

# 28. Print total time and summary
print_total_time

# Final verification
step 28 "Final verification and testing"
execute_ssh "cd $APP_DIR && docker compose -f docker/docker-compose.yml ps"
echo ""
echo "ðŸ”— Your site should be available at:"
echo "   - http://harun.dev"
echo "   - http://$PUBLIC_IP"
echo ""
echo "ðŸ”§ Traefik dashboard: http://$PUBLIC_IP:8080"
echo ""
echo "ðŸ“‹ To check logs:"
echo "   ssh -i $SSH_KEY $REMOTE_USER@$PUBLIC_IP 'cd $APP_DIR && docker compose -f docker/docker-compose.yml logs -f'"
