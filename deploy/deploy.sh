#!/bin/bash

set -e
set -o pipefail

# Get absolute path to script directory, regardless of where it's called from
SCRIPT_DIR="$( cd -- "$( dirname -- "${BASH_SOURCE[0]}" )" &> /dev/null && pwd )"
REPO_ROOT="$(dirname "$SCRIPT_DIR")"

# Usage:
#   ./deploy.sh [KEY=VALUE ...]
#   Example: ./deploy.sh APP_DEBUG=true FOO=bar
# Any key=value pairs passed as arguments will take highest priority in the generated .env file.
# The .env file is generated by merging, in order of precedence (lowest to highest):
#   1. .env.example (base)
#   2. deploy/.env.appprod (if exists)
#   3. deploy/.env.deploy (if exists)
#   4. Inline key=value arguments (provided at runtime)

# Set up logging
LOG_DIR="$SCRIPT_DIR/log"
mkdir -p "$LOG_DIR"
# Archive previous deploy.log if it exists
if [ -f "$LOG_DIR/deploy.log" ]; then
  mv "$LOG_DIR/deploy.log" "$LOG_DIR/deploy-$(date '+%Y%m%d-%H%M%S').log"
fi
LOG_FILE="$LOG_DIR/deploy.log"
exec > >(tee -a "$LOG_FILE") 2>&1

# Load environment variables
if [ -f "$SCRIPT_DIR/.env.deploy" ]; then
  set -a
  . "$SCRIPT_DIR/.env.deploy"
  set +a
fi

# Ensure SSH_KEY is relative to the deploy directory
if [ -n "$SSH_KEY" ] && [[ "$SSH_KEY" != /* ]]; then
  SSH_KEY="$SCRIPT_DIR/$SSH_KEY"
fi

echo "[DEBUG] SSH_KEY resolved to: $SSH_KEY"

# Colors have been completely removed

# Signature and start time
SCRIPT_START_TIME=$(date +%s)
echo -e "\n==============================================="
echo -e "   ðŸš€ Harun's Portfolio Deployment Script ðŸš€"
echo -e "===============================================\n"
echo "Started at: $(date)"

# Remove associative array, use indexed array for step times
STEP_TIMES=()

# Helper: Print step header, track and print step time
step() {
  STEP_NUM=$1
  STEP_NAME="$2"
  echo -e "\n+++++++++++++++++++++++++++++++++++++++++++++++"
  printf '+++   STEP %d: %s   +++\n' "$STEP_NUM" "$STEP_NAME"
  echo -e "++++++++++++++++++++++++++++++++++++++++++++++\n"
  STEP_START_TIME=$(date +%s)
}

# Helper: Print success info to terminal only
success() {
  echo -e "$1"
  STEP_END_TIME=$(date +%s)
  STEP_DURATION=$((STEP_END_TIME - STEP_START_TIME))
  echo -e "Step took $STEP_DURATION seconds.\n"
  STEP_TIMES+=("$STEP_DURATION")
}

# Helper: Print error info to terminal only
fail() {
  echo -e "$1"
  STEP_END_TIME=$(date +%s)
  STEP_DURATION=$((STEP_END_TIME - STEP_START_TIME))
  echo -e "Step took $STEP_DURATION seconds.\n"
  STEP_TIMES+=("$STEP_DURATION")
}

# At the end, print total time
print_total_time() {
  SCRIPT_END_TIME=$(date +%s)
  TOTAL_DURATION=$((SCRIPT_END_TIME - SCRIPT_START_TIME))
  echo -e "\n==============================================="
  echo -e "   ðŸŽ‰ Deployment completed in $TOTAL_DURATION seconds! ðŸŽ‰"
  echo -e "===============================================\n"
  for i in $(seq 1 ${#STEP_TIMES[@]}); do
    echo "Step $i took: ${STEP_TIMES[$((i-1))]:-N/A} seconds"
  done
}

# Function to execute SSH commands
execute_ssh() {
    ssh -o StrictHostKeyChecking=no -i "$SSH_KEY" "$REMOTE_USER@$REMOTE_HOST" "$1"
}

# Function to clone or update the git repository on the server
clone_or_update_repo() {
    execute_ssh "if [ ! -d $APP_DIR/.git ]; then \
        if [ -d $APP_DIR ]; then \
            rm -rf $APP_DIR/* $APP_DIR/.[!.]* $APP_DIR/..?* 2>/dev/null || true; \
        else \
            mkdir -p $APP_DIR; \
        fi; \
        git clone --branch $GIT_BRANCH $GIT_REPO $APP_DIR; \
    else \
        cd $APP_DIR && git fetch origin && git checkout $GIT_BRANCH && git pull origin $GIT_BRANCH; \
    fi"
}

# Function to robustly merge env files
merge_env_files() {
    # $1 = base file, $2 = override file, $3 = output file
    if ! cmp -s "$1" "$3"; then
        cp "$1" "$3"
    fi
    if [ -f "$2" ]; then
        while IFS= read -r line; do
            # Only process non-empty, non-comment lines
            if [[ "$line" =~ ^[A-Za-z_][A-Za-z0-9_]*= ]]; then
                key="${line%%=*}"
                # Remove any existing key (even if commented out)
                sed -i '' "/^$key=/d" "$3"
                # Append the new/override value
                echo "$line" >> "$3"
            fi
        done < "$2"
    fi
}

# Helper: Overlay only inline-provided envs (those set on the command line)
overlay_inline_envs() {
    # Save current IFS
    OLDIFS=$IFS
    IFS=' '
    # Get the list of inline envs from the command line
    for arg in $(ps -o args= -p $$); do
        if [[ "$arg" =~ ^[A-Za-z_][A-Za-z0-9_]*= ]]; then
            key="${arg%%=*}"
            value="${arg#*=}"
            sed -i '' "/^$key=/d" "$SCRIPT_DIR/.env"
            echo "$key=$value" >> "$SCRIPT_DIR/.env"
        fi
    done
    IFS=$OLDIFS
}

# Add this helper function near the top of the script
wait_for_app_container() {
  local timeout=60
  local elapsed=0
  while [ $elapsed -lt $timeout ]; do
    DOCKER_COMPOSE_CMD=$(docker_compose_run "./docker/docker-compose.yml" "ps --services --filter 'status=running' | grep '^app$'")
    STATUS=$(execute_ssh "cd $APP_DIR && $DOCKER_COMPOSE_CMD")
    if [ "$STATUS" = "app" ]; then
      return 0
    fi
    sleep 2
    elapsed=$((elapsed+2))
  done
  echo "App container did not start within $timeout seconds." >&2
  return 1
}

wait_forcheck_app_container_running() {
  local timeout=60
  local elapsed=0
  while [ $elapsed -lt $timeout ]; do
    DOCKER_COMPOSE_CMD=$(docker_compose_run "./docker/docker-compose.yml" "ps --services --filter 'status=running' | grep '^app$'")
    STATUS=$(execute_ssh "cd $APP_DIR && $DOCKER_COMPOSE_CMD")
    if [ "$STATUS" = "app" ]; then
      return 0
    fi
    sleep 1
    elapsed=$((elapsed + 1))
  done
  echo "App container did not start within $timeout seconds." >&2
  return 1
}

#-------------------------------------------------------------------------------
# Helper Functions
#-------------------------------------------------------------------------------
# Function to generate Docker environment variables string
get_docker_env_vars() {
  echo "POSTGRES_DB=$POSTGRES_DB \
  POSTGRES_USER=$POSTGRES_USER \
  POSTGRES_PASSWORD=$POSTGRES_PASSWORD \
  MIN_APP_INSTANCES=$MIN_APP_INSTANCES \
  MAX_APP_INSTANCES=$MAX_APP_INSTANCES \
  APP_CPU_LIMIT=$APP_CPU_LIMIT \
  APP_MEMORY_LIMIT=$APP_MEMORY_LIMIT \
  NGINX_CPU_LIMIT=$NGINX_CPU_LIMIT \
  NGINX_MEMORY_LIMIT=$NGINX_MEMORY_LIMIT \
  DB_CPU_LIMIT=$DB_CPU_LIMIT \
  DB_MEMORY_LIMIT=$DB_MEMORY_LIMIT \
  MAX_APP_CPU_LIMIT=$MAX_APP_CPU_LIMIT \
  MAX_APP_MEMORY_LIMIT=$MAX_APP_MEMORY_LIMIT \
  MAX_NGINX_CPU_LIMIT=$MAX_NGINX_CPU_LIMIT \
  MAX_NGINX_MEMORY_LIMIT=$MAX_NGINX_MEMORY_LIMIT \
  MAX_DB_CPU_LIMIT=$MAX_DB_CPU_LIMIT \
  MAX_DB_MEMORY_LIMIT=$MAX_DB_MEMORY_LIMIT"
}

# Execute Docker Compose command with proper environment variables
docker_compose_exec() {
  local compose_file="$1"
  local service="$2"
  local command="$3"
  local docker_env_vars=$(get_docker_env_vars)

  echo "$docker_env_vars docker-compose -f $compose_file exec -T $service $command"
}

# Run Docker Compose command with proper environment variables
docker_compose_run() {
  local compose_file="$1"
  local command="$2"
  local docker_env_vars=$(get_docker_env_vars)

  echo "$docker_env_vars docker-compose -f $compose_file $command"
}

# 1. Start
step 1 "Starting deployment"
echo "[DEBUG] SSH_KEY resolved to: $SSH_KEY"

# 2. Initialize server with required directories and Docker
step 2 "Initializing server with required directories and Docker"

# Create required directories if they don't exist
execute_ssh "sudo mkdir -p $APP_DIR"
execute_ssh "sudo chown -R ubuntu:ubuntu $APP_DIR || true"

# Check if Docker is installed, install if not
execute_ssh "if ! command -v docker &> /dev/null; then
  echo 'Docker not found, installing...'
  sudo apt-get update
  sudo apt-get install -y apt-transport-https ca-certificates curl software-properties-common
  curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
  sudo add-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/ubuntu \$(lsb_release -cs) stable\"
  sudo apt-get update
  sudo apt-get install -y docker-ce docker-ce-cli containerd.io docker-compose-plugin
  sudo systemctl enable docker
  sudo systemctl start docker
  sudo usermod -aG docker ubuntu
  echo 'Docker installed successfully'
fi"

# 3. Ensure ubuntu user is in the docker group for Docker access
step 3 "Ensuring ubuntu user is in the docker group"
execute_ssh "sudo usermod -aG docker ubuntu"

# 4. Generate .env file from .env.example, .env.appprod, and deploy variables
step 4 "Generating .env file from .env.example, .env.appprod, and deploy variables"
merge_env_files "$REPO_ROOT/.env.example" "$SCRIPT_DIR/.env.appprod" "$SCRIPT_DIR/.env"
merge_env_files "$SCRIPT_DIR/.env" "$SCRIPT_DIR/.env.deploy" "$SCRIPT_DIR/.env"
for arg in "$@"; do
    if [[ "$arg" =~ ^[A-Za-z_][A-Za-z0-9_]*= ]]; then
        key="${arg%%=*}"
        value="${arg#*=}"
        grep -v "^$key=" "$SCRIPT_DIR/.env" > "$SCRIPT_DIR/.env.tmp" && mv "$SCRIPT_DIR/.env.tmp" "$SCRIPT_DIR/.env"
        echo "$key=$value" >> "$SCRIPT_DIR/.env"
    fi
done
# Clean up .env: only keep valid KEY=VALUE lines, one per line
sed -i.bak -n '/^[A-Za-z_][A-Za-z0-9_]*=.*/p' "$SCRIPT_DIR/.env"
rm -f "$SCRIPT_DIR/.env.bak"
# Copy the generated .env to the repo root for Docker build
cp "$SCRIPT_DIR/.env" "$REPO_ROOT/.env"

# 5. Ensure resources/views exists with a real Blade placeholder for Laravel
step 5 "Ensuring resources/views exists with placeholder"
mkdir -p "$REPO_ROOT/resources/views"
if [ ! -f "$REPO_ROOT/resources/views/placeholder.blade.php" ]; then
  echo "{{-- Placeholder view to satisfy Laravel --}}" > "$REPO_ROOT/resources/views/placeholder.blade.php"
fi

# 6. Check Node.js version before build
step 6 "Checking Node.js version"

# Check if nvm is installed
if ! command -v nvm &> /dev/null; then
  echo "nvm not found, attempting to source from common locations..."

  # Try to source nvm from common locations
  if [ -s "$HOME/.nvm/nvm.sh" ]; then
    . "$HOME/.nvm/nvm.sh"
  elif [ -s "$NVM_DIR/nvm.sh" ]; then
    . "$NVM_DIR/nvm.sh"
  elif [ -s "/usr/local/opt/nvm/nvm.sh" ]; then
    . "/usr/local/opt/nvm/nvm.sh"
  fi

  # Check again after sourcing
  if ! command -v nvm &> /dev/null; then
    echo "Installing nvm..."
    curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.7/install.sh | bash

    # Source nvm after installation
    export NVM_DIR="$HOME/.nvm"
    [ -s "$NVM_DIR/nvm.sh" ] && \. "$NVM_DIR/nvm.sh"
  fi
fi

# Check Node.js version
NODE_VERSION=$(node -v 2>/dev/null | sed 's/v//;s/\..*//' || echo "0")
if [ "$NODE_VERSION" -lt 18 ]; then
  echo "Node.js >= 18 is required. Current: $(node -v 2>/dev/null || echo 'not installed')"

  if command -v nvm &> /dev/null; then
    echo "Attempting to switch to Node.js LTS using nvm..."
    nvm install --lts
    nvm use --lts

    # Check version again after nvm use
    NODE_VERSION=$(node -v | sed 's/v//;s/\..*//')
    if [ "$NODE_VERSION" -lt 18 ]; then
      fail "Failed to switch to Node.js >= 18 using nvm. Please install Node.js >= 18 manually."
      exit 1
    else
      echo "Successfully switched to Node.js $(node -v) using nvm."
    fi
  else
    fail "nvm is not available after installation attempt. Please install Node.js >= 18 manually."
    exit 1
  fi
fi

# 7. Build frontend locally
step 7 "Building frontend locally"
cd "$REPO_ROOT"

# Empty out public/build/assets if it exists
if [ -d "public/build/assets" ]; then
  echo "[INFO] Emptying public/build/assets before build..."
  rm -rf public/build/assets/*
fi

# Backup existing .env file if it exists
if [ -f "$REPO_ROOT/.env" ]; then
  echo "[INFO] Backing up existing .env file..."
  cp "$REPO_ROOT/.env" "$REPO_ROOT/.env.backup"
fi

# Copy .env.appprod to .env for the build process
cp "$SCRIPT_DIR/.env.appprod" "$REPO_ROOT/.env"

npm ci && npm run build
BUILD_STATUS=$?

# Restore the original .env file if backup exists
if [ -f "$REPO_ROOT/.env.backup" ]; then
  echo "[INFO] Restoring original .env file..."
  cp "$REPO_ROOT/.env.backup" "$REPO_ROOT/.env"
  rm "$REPO_ROOT/.env.backup"
fi

cd "$SCRIPT_DIR"
if [ $BUILD_STATUS -ne 0 ]; then
  fail "Frontend build failed. Aborting deploy."
  exit 1
fi

# 8. Upload static assets to Cloudflare R2
step 8 "Uploading static assets to Cloudflare R2"
if [ -z "$R2_BUCKET_NAME" ] || [ -z "$R2_S3_ENDPOINT" ] || [ -z "$R2_ACCESS_KEY_ID" ] || [ -z "$R2_SECRET_ACCESS_KEY" ]; then
  fail "R2_BUCKET_NAME, R2_S3_ENDPOINT, R2_ACCESS_KEY_ID, or R2_SECRET_ACCESS_KEY not set. Aborting."
  exit 1
fi

export AWS_ACCESS_KEY_ID="$R2_ACCESS_KEY_ID"
export AWS_SECRET_ACCESS_KEY="$R2_SECRET_ACCESS_KEY"

# Ensure proper content types for different file types
echo "Uploading build assets with proper content types..."
aws s3 sync "$REPO_ROOT/public/build" "s3://$R2_BUCKET_NAME/build" --endpoint-url "$R2_S3_ENDPOINT" --delete --acl public-read

# Upload JS files with proper content type
echo "Setting proper content types for JavaScript files..."
find "$REPO_ROOT/public/build" -name "*.js" -type f | while read -r file; do
  relative_path="${file#$REPO_ROOT/public/}"
  aws s3 cp "$file" "s3://$R2_BUCKET_NAME/$relative_path" --endpoint-url "$R2_S3_ENDPOINT" --content-type "application/javascript" --acl public-read
done

# Upload CSS files with proper content type
echo "Setting proper content types for CSS files..."
find "$REPO_ROOT/public/build" -name "*.css" -type f | while read -r file; do
  relative_path="${file#$REPO_ROOT/public/}"
  aws s3 cp "$file" "s3://$R2_BUCKET_NAME/$relative_path" --endpoint-url "$R2_S3_ENDPOINT" --content-type "text/css" --acl public-read
done

# Upload other static assets
aws s3 sync "$REPO_ROOT/public/fonts" "s3://$R2_BUCKET_NAME/fonts" --endpoint-url "$R2_S3_ENDPOINT" --delete --acl public-read
aws s3 sync "$REPO_ROOT/public/images" "s3://$R2_BUCKET_NAME/images" --endpoint-url "$R2_S3_ENDPOINT" --delete --acl public-read

success "Static assets uploaded to Cloudflare R2."

# 9. Clone or update repo on server
step 9 "Cloning or updating repository on server"
clone_or_update_repo

# Check for required Docker context files after clone
execute_ssh "if [ ! -f $APP_DIR/docker/Dockerfile ] || [ ! -f $APP_DIR/docker/wait-for-db.sh ]; then echo '[ERROR] Required Docker context files missing after git clone. Ensure docker/Dockerfile and docker/wait-for-db.sh are committed to the repo.' >&2; exit 1; fi"

# 10. Ensure host storage directory has correct structure and permissions (after clone)
step 10 "Ensuring host storage directory structure and permissions"
HOST_STORAGE_DIR="/opt/portfolio/storage"
execute_ssh "if [ -d '$HOST_STORAGE_DIR' ]; then \
  mkdir -p '$HOST_STORAGE_DIR/framework/views' '$HOST_STORAGE_DIR/framework/cache' '$HOST_STORAGE_DIR/logs'; \
  sudo chown -R 82:82 '$HOST_STORAGE_DIR'; \
  sudo chmod -R 775 '$HOST_STORAGE_DIR'; \
else \
  echo '[WARN] Host storage directory $HOST_STORAGE_DIR does not exist!'; \
fi"

# 11. Upload remaining public files to server (excluding build, fonts, images)
step 11 "Uploading remaining public files to server"
# Only upload files in public/ that are not in build, fonts, images
tmp_sync_dir="$SCRIPT_DIR/public-server-sync"
rm -rf "$tmp_sync_dir"
mkdir -p "$tmp_sync_dir"
cd "$REPO_ROOT/public"
find . -maxdepth 1 -type f -exec cp {} "$tmp_sync_dir/" \;
# Always include manifest.json if it exists in build
test -f "$REPO_ROOT/public/build/manifest.json" && cp "$REPO_ROOT/public/build/manifest.json" "$tmp_sync_dir/"
cd "$SCRIPT_DIR"
tar --no-xattrs -czf public-server-files.tar.gz -C "$tmp_sync_dir" .
scp -o StrictHostKeyChecking=no -i "$SSH_KEY" public-server-files.tar.gz "$REMOTE_USER@$REMOTE_HOST:$APP_DIR/public-server-files.tar.gz"
execute_ssh "mkdir -p $APP_DIR/public && tar xzf $APP_DIR/public-server-files.tar.gz -C $APP_DIR/public && rm $APP_DIR/public-server-files.tar.gz"
rm -rf "$tmp_sync_dir" public-server-files.tar.gz

success "Remaining public files uploaded to server."

# 12. Set up docker env on the server & start containers
step 12 "Setting up docker environment on server & starting containers"
execute_ssh "mkdir -p $APP_DIR/deploy/docker $APP_DIR/bootstrap/cache $APP_DIR/storage $APP_DIR/storage/logs $APP_DIR/storage/framework/sessions $APP_DIR/storage/framework/views $APP_DIR/storage/framework/cache $APP_DIR/storage/framework/cache/data"
# Don't try to chmod directly - we'll handle permissions through Docker
# Ensure nginx.conf is a file, not a directory
execute_ssh "if [ -d $APP_DIR/deploy/docker/nginx.conf ]; then rm -rf $APP_DIR/deploy/docker/nginx.conf; fi"
scp -o StrictHostKeyChecking=no -i "$SSH_KEY" "$REPO_ROOT/docker/nginx.conf" "$REMOTE_USER@$REMOTE_HOST:$APP_DIR/deploy/docker/nginx.conf"
scp -o StrictHostKeyChecking=no -i "$SSH_KEY" "$REPO_ROOT/docker/docker-compose.yml" "$REMOTE_USER@$REMOTE_HOST:$APP_DIR/deploy/docker/docker-compose.yml"
# Ensure Dockerfile and wait-for-db.sh are present
scp -o StrictHostKeyChecking=no -i "$SSH_KEY" "$REPO_ROOT/docker/Dockerfile" "$REMOTE_USER@$REMOTE_HOST:$APP_DIR/deploy/docker/Dockerfile"
scp -o StrictHostKeyChecking=no -i "$SSH_KEY" "$REPO_ROOT/docker/wait-for-db.sh" "$REMOTE_USER@$REMOTE_HOST:$APP_DIR/deploy/docker/wait-for-db.sh"

# 13. Copy .env file
step 13 "Copying .env file"
# Remove any existing .env on the server before copying
execute_ssh "rm -f $APP_DIR/.env"
scp -o StrictHostKeyChecking=no -i "$SSH_KEY" "$REPO_ROOT/.env" "$REMOTE_USER@$REMOTE_HOST:$APP_DIR/.env"

# Ensure manifest.json is present before Docker build
execute_ssh "mkdir -p $APP_DIR/public/build"
scp -o StrictHostKeyChecking=no -i "$SSH_KEY" "$REPO_ROOT/public/build/manifest.json" "$REMOTE_USER@$REMOTE_HOST:$APP_DIR/public/build/manifest.json"

# 14. Generate SSL cert and key on the server if not present
step 14 "Ensuring SSL certificate and key exist on server"
SSL_PATH="/etc/nginx/ssl"
SSL_CRT="$SSL_PATH/harun.dev.crt"
SSL_KEY="$SSL_PATH/harun.dev.key"
execute_ssh "sudo mkdir -p $SSL_PATH && \
  if [ ! -f $SSL_CRT ] || [ ! -f $SSL_KEY ]; then \
    sudo openssl req -x509 -nodes -days 365 -newkey rsa:2048 \
      -keyout $SSL_KEY -out $SSL_CRT \
      -subj '/CN=harun.dev'; \
    sudo chmod 600 $SSL_CRT $SSL_KEY && sudo chown root:root $SSL_CRT $SSL_KEY; \
  fi"

# 15. Ensure required Laravel cache and storage directories exist and are writable by www-data
step 15 "Ensuring Laravel cache and storage directories exist and are writable"
execute_ssh "cd $APP_DIR && \
  mkdir -p storage/framework/views storage/framework/cache storage/logs bootstrap/cache && \
  sudo chown -R www-data:www-data storage bootstrap/cache && \
  sudo chmod -R 775 storage bootstrap/cache"

# 16. Execute deployment commands
step 16 "Executing deployment commands"
# Create a multi-line command with proper Docker environment variables
DOCKER_COMPOSE_FILE="./deploy/docker/docker-compose.yml"
DOCKER_DOWN_CMD=$(docker_compose_run "$DOCKER_COMPOSE_FILE" "down")
DOCKER_BUILD_CMD=$(docker_compose_run "$DOCKER_COMPOSE_FILE" "build --no-cache")
DOCKER_UP_CMD=$(docker_compose_run "$DOCKER_COMPOSE_FILE" "up -d")
DOCKER_PS_CMD=$(docker_compose_run "$DOCKER_COMPOSE_FILE" "ps | grep app")

# Execute the commands in sequence
execute_ssh "cd $APP_DIR && \
    $DOCKER_DOWN_CMD && \
    $DOCKER_BUILD_CMD && \
    $DOCKER_UP_CMD && \
    $DOCKER_PS_CMD"
# Remove the .env from the repo root after build
rm -f "$REPO_ROOT/.env"

# Update APP_KEY in .env on the server
# Generate Laravel application key
DOCKER_KEY_CMD=$(docker_compose_exec "./docker/docker-compose.yml" "app" "php artisan key:generate --show")
execute_ssh "cd $APP_DIR && APP_KEY=\$(${DOCKER_KEY_CMD}) && \
    echo Found APP_KEY: \$APP_KEY && \
    (grep -q '^APP_KEY=' .env && sed -i 's|^APP_KEY=.*|APP_KEY=\$APP_KEY|' .env || echo APP_KEY=\$APP_KEY >> .env)"

# Run Laravel artisan commands for optimization and setup
DOCKER_COMPOSE_FILE="./deploy/docker/docker-compose.yml"

# Create command variables for each artisan command
CONFIG_CACHE_CMD=$(docker_compose_exec "$DOCKER_COMPOSE_FILE" "app" "php artisan config:cache")
ROUTE_CACHE_CMD=$(docker_compose_exec "$DOCKER_COMPOSE_FILE" "app" "php artisan route:cache")
VIEW_CACHE_CMD=$(docker_compose_exec "$DOCKER_COMPOSE_FILE" "app" "php artisan view:cache")
MIGRATE_CMD=$(docker_compose_exec "$DOCKER_COMPOSE_FILE" "app" "php artisan migrate --force")
# Check if storage link already exists before creating it
STORAGE_LINK_CMD=$(docker_compose_exec "$DOCKER_COMPOSE_FILE" "app" "sh -c \"if [ ! -L /var/www/html/public/storage ]; then php artisan storage:link; else echo 'Storage link already exists, skipping creation'; fi\"")

# Fix permissions for Laravel cache directories - using Docker to handle permissions with a single command
execute_ssh "cd $APP_DIR && $(docker_compose_run "$DOCKER_COMPOSE_FILE" "exec -T app sh -c 'mkdir -p /var/www/html/bootstrap/cache /var/www/html/storage/framework/cache /var/www/html/storage/framework/cache/data /var/www/html/storage/framework/sessions /var/www/html/storage/framework/views /var/www/html/storage/logs && chown -R www-data:www-data /var/www/html/storage /var/www/html/bootstrap/cache && chmod -R 777 /var/www/html/storage /var/www/html/bootstrap/cache'")"

# Execute artisan commands as a single command to avoid syntax issues
COMBINED_ARTISAN_CMD="cd $APP_DIR && $CONFIG_CACHE_CMD && $ROUTE_CACHE_CMD && $VIEW_CACHE_CMD && $MIGRATE_CMD && $STORAGE_LINK_CMD"
execute_ssh "$COMBINED_ARTISAN_CMD"

# 17. Check app container status
step 17 "Checking app container status"
if ! wait_for_app_container; then
  fail "App container did not start in time. Aborting deploy."
  exit 1
fi

# 18. Ensure wait-for-db.sh is executable in the container
step 18 "Ensuring wait-for-db.sh is executable in the container"
echo -e "\n+++++++++++++++++++++++++++++++++++++++++++++++\n+++   STEP 18: Ensuring wait-for-db.sh is executable in the container   +++\n++++++++++++++++++++++++++++++++++++++++++++++\n"
execute_ssh "cd $APP_DIR && sudo docker exec \$(sudo docker ps -qf 'name=app' | head -n 1) sh -c 'chmod +x ./wait-for-db.sh && php artisan cache:clear'"

# 18.1. Ensure proper Laravel cache configuration
echo -e "\n+++++++++++++++++++++++++++++++++++++++++++++++\n+++   STEP 18.1: Ensuring proper Laravel cache configuration   +++\n++++++++++++++++++++++++++++++++++++++++++++++\n"

# Create all required Laravel cache directories with proper permissions and add .gitkeep files to ensure they exist
execute_ssh "cd $APP_DIR && sudo docker exec \$(sudo docker ps -qf 'name=app' | head -n 1) sh -c '\
    # Create all required Laravel directory structure\
    mkdir -p /var/www/html/storage/app/public \
    /var/www/html/storage/framework/cache \
    /var/www/html/storage/framework/cache/data \
    /var/www/html/storage/framework/sessions \
    /var/www/html/storage/framework/testing \
    /var/www/html/storage/framework/views \
    /var/www/html/storage/logs \
    /var/www/html/bootstrap/cache && \
    \
    # Add .gitkeep files to ensure directories exist and are tracked\
    touch /var/www/html/storage/framework/cache/.gitkeep \
    /var/www/html/storage/framework/cache/data/.gitkeep \
    /var/www/html/storage/framework/sessions/.gitkeep \
    /var/www/html/storage/framework/testing/.gitkeep \
    /var/www/html/storage/framework/views/.gitkeep \
    /var/www/html/storage/logs/.gitkeep \
    /var/www/html/bootstrap/cache/.gitkeep && \
    \
    # Set proper permissions\
    chmod -R 777 /var/www/html/storage && \
    chmod -R 777 /var/www/html/bootstrap/cache && \
    chown -R www-data:www-data /var/www/html/storage /var/www/html/bootstrap/cache && \
    \
    # Ensure cache driver is set to file in the .env file\
    grep -q "CACHE_DRIVER=file" /var/www/html/.env || sed -i "s/CACHE_DRIVER=.*/CACHE_DRIVER=file/" /var/www/html/.env'"

# The view.php configuration file is now part of the git repository
# No need to upload it separately as it will be included during git clone/pull

# Ensure cache driver is set to file
execute_ssh "cd $APP_DIR && sudo sed -i 's/CACHE_DRIVER=.*/CACHE_DRIVER=file/' .env"

# Copy view.php from local repository to server and then to Docker container
scp -o StrictHostKeyChecking=no -i "$SSH_KEY" "$REPO_ROOT/config/view.php" "$REMOTE_USER@$REMOTE_HOST:$APP_DIR/config/view.php"
execute_ssh "cd $APP_DIR && sudo docker exec \$(sudo docker ps -qf 'name=app' | head -n 1) sh -c 'mkdir -p /var/www/html/config' && \
sudo docker cp ./config/view.php \$(sudo docker ps -qf 'name=app' | head -n 1):/var/www/html/config/view.php && \
sudo docker exec \$(sudo docker ps -qf 'name=app' | head -n 1) sh -c 'chown www-data:www-data /var/www/html/config/view.php && chmod 644 /var/www/html/config/view.php'"

# Create all required cache directories with proper permissions
execute_ssh "cd $APP_DIR && sudo docker exec \$(sudo docker ps -qf 'name=app' | head -n 1) sh -c 'mkdir -p /var/www/html/storage/framework/views /var/www/html/storage/framework/cache/data /var/www/html/storage/framework/sessions /var/www/html/bootstrap/cache && \
chmod -R 777 /var/www/html/storage && \
chmod -R 777 /var/www/html/bootstrap/cache && \
chown -R www-data:www-data /var/www/html/storage /var/www/html/bootstrap/cache'"

# Ensure the VIEW_COMPILED_PATH is correctly set in the environment
execute_ssh "cd $APP_DIR && sudo docker exec \$(sudo docker ps -qf 'name=app' | head -n 1) sh -c 'export VIEW_COMPILED_PATH=/var/www/html/storage/framework/views && echo VIEW_COMPILED_PATH is set to /var/www/html/storage/framework/views'"

# Clear all caches
execute_ssh "cd $APP_DIR && sudo docker exec \$(sudo docker ps -qf 'name=app' | head -n 1) sh -c 'php artisan config:clear && \
php artisan view:clear'"

# Verify cache directory structure and permissions
execute_ssh "cd $APP_DIR && sudo docker exec \$(sudo docker ps -qf 'name=app' | head -n 1) sh -c 'ls -la /var/www/html/storage/framework/cache && ls -la /var/www/html/storage/framework/cache/data && ls -la /var/www/html/storage/framework/views && ls -la /var/www/html/bootstrap/cache && ls -la /var/www/html/config/view.php'"

# Double-check that all cache directories exist with proper permissions
execute_ssh "cd $APP_DIR && sudo docker exec \$(sudo docker ps -qf 'name=app' | head -n 1) sh -c 'mkdir -p /var/www/html/storage/framework/cache/data /var/www/html/storage/framework/sessions /var/www/html/storage/framework/views /var/www/html/storage/logs /var/www/html/bootstrap/cache && \
chmod -R 777 /var/www/html/storage && \
chmod -R 777 /var/www/html/bootstrap/cache && \
chown -R www-data:www-data /var/www/html/storage /var/www/html/bootstrap/cache'"

# Verify the VIEW_COMPILED_PATH is set in the .env file
execute_ssh "cd $APP_DIR && sudo docker exec \$(sudo docker ps -qf 'name=app' | head -n 1) sh -c 'grep VIEW_COMPILED_PATH /var/www/html/.env'"

# Clear all caches and then rebuild them
execute_ssh "cd $APP_DIR && sudo docker exec \$(sudo docker ps -qf 'name=app' | head -n 1) sh -c 'php artisan config:clear && \
php artisan view:clear && \
php artisan route:clear && \
php artisan optimize:clear && \
php artisan config:cache && \
php artisan route:cache && \
php artisan view:cache'"

# 19. Wait for the database to be ready
step 19 "Waiting for the database to be ready inside the app container"
echo "Database connection is assumed to be ready (skipping wait-for-db.sh)"
# Skip the wait-for-db.sh script as it's causing issues
# DOCKER_WAIT_DB_CMD=$(docker_compose_exec "./docker/docker-compose.yml" "app" "./wait-for-db.sh db 5432 60")
# execute_ssh "cd $APP_DIR && $DOCKER_WAIT_DB_CMD"

# Fix Laravel storage permissions using a single command to avoid syntax issues
# Ensure ALL cache directories exist with proper permissions
execute_ssh "cd $APP_DIR && $(docker_compose_run "./docker/docker-compose.yml" "exec -T app sh -c 'mkdir -p /var/www/html/storage/framework/cache/data /var/www/html/storage/framework/sessions /var/www/html/storage/framework/views /var/www/html/storage/logs /var/www/html/bootstrap/cache && chmod -R 777 /var/www/html/storage && chmod -R 777 /var/www/html/bootstrap/cache && chown -R www-data:www-data /var/www/html/storage /var/www/html/bootstrap/cache'")"

# Double-check that the cache directory structure is correct
execute_ssh "cd $APP_DIR && $(docker_compose_run "./docker/docker-compose.yml" "exec -T app sh -c 'ls -la /var/www/html/storage/framework/cache/data'")"

# 20 Test DB connection from app container
step 20 "Testing database connection from app container"
# Test database connection
DOCKER_MIGRATE_STATUS_CMD=$(docker_compose_exec "./docker/docker-compose.yml" "app" "php artisan migrate:status")
execute_ssh "cd $APP_DIR && $DOCKER_MIGRATE_STATUS_CMD"

success "Deployment completed!"

# 21. Skip Cloudflare Worker R2 Bucket Binding (already done by Terraform)
step 21 "Skipping Cloudflare Worker R2 Bucket Binding (already done by Terraform)"

echo "Skipping Cloudflare Worker R2 bucket binding as it's already configured by Terraform during infrastructure creation."

# 22. Purge CDN Cache (Cloudflare)
step 22 "Purging CDN Cache (Cloudflare)"
if [ -z "$CLOUDFLARE_ZONE_ID" ] || [ -z "$CLOUDFLARE_API_TOKEN" ]; then
  echo "Skipping Cloudflare CDN purge - missing CLOUDFLARE_ZONE_ID or CLOUDFLARE_API_TOKEN"
  echo "To enable Cloudflare cache purging, add the following to your .env.deploy file:"
  echo "CLOUDFLARE_API_TOKEN=your_api_token"
  echo "CLOUDFLARE_ZONE_ID=your_zone_id"
else
  echo "Attempting to purge Cloudflare cache for zone ID $CLOUDFLARE_ZONE_ID"
  if [ -n "$CLOUDFLARE_API_TOKEN" ]; then
    echo "Using API Token authentication method..."
    RESULT=$(curl -s -X POST \
      "https://api.cloudflare.com/client/v4/zones/$CLOUDFLARE_ZONE_ID/purge_cache" \
      -H "Authorization: Bearer $CLOUDFLARE_API_TOKEN" \
      -H "Content-Type: application/json" \
      --data '{"purge_everything":true}')

    # Parse JSON properly to check for success
    SUCCESS=$(echo "$RESULT" | grep -o '"success":[^,}]*' | cut -d ':' -f2 | tr -d ' ')
    if [[ "$SUCCESS" == "true" ]]; then
      echo "Cloudflare cache purged successfully!"
    else
      echo "Failed to purge Cloudflare cache. Response: $RESULT"
    fi
  elif [ -n "$CLOUDFLARE_EMAIL" ] && [ -n "$CLOUDFLARE_API_KEY" ]; then
    echo "Using API Key authentication method..."
    RESULT=$(curl -s -X POST \
      "https://api.cloudflare.com/client/v4/zones/$CLOUDFLARE_ZONE_ID/purge_cache" \
      -H "X-Auth-Email: $CLOUDFLARE_EMAIL" \
      -H "X-Auth-Key: $CLOUDFLARE_API_KEY" \
      -H "Content-Type: application/json" \
      --data '{"purge_everything":true}')

    # Parse JSON properly to check for success
    SUCCESS=$(echo "$RESULT" | grep -o '"success":[^,}]*' | cut -d ':' -f2 | tr -d ' ')
    if [[ "$SUCCESS" == "true" ]]; then
      echo "Cloudflare cache purged successfully!"
    else
      echo "Failed to purge Cloudflare cache. Response: $RESULT"
    fi
  else
    echo "Missing Cloudflare authentication credentials. Please provide either API Token or Email + API Key."
  fi
fi

# 23. Print total time and summary
print_total_time
